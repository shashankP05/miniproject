# Import necessary libraries
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.datasets import mnist
from tensorflow.keras.models import Sequential, Model
from tensorflow.keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose
from tensorflow.keras.optimizers import Adam

# Load MNIST dataset
(X_train, _), (_, _) = mnist.load_data()

# Normalize data
X_train = X_train.astype('float32') / 255.0

# Define the generator model
def build_generator():
    model = Sequential()
    model.add(Dense(128 * 7 * 7, activation='relu', input_dim=100))
    model.add(Reshape((7, 7, 128)))
    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding='same', activation='relu'))
    model.add(Conv2DTranspose(1, kernel_size=4, strides=2, padding='same', activation='sigmoid'))
    return model

# Define the discriminator model
def build_discriminator():
    model = Sequential()
    model.add(Conv2D(64, kernel_size=3, strides=2, input_shape=(28, 28, 1), padding='same', activation='relu'))
    model.add(Conv2D(128, kernel_size=3, strides=2, padding='same', activation='relu'))
    model.add(Flatten())
    model.add(Dense(1, activation='sigmoid'))
    return model

# Define the combined GAN model
def build_gan(generator, discriminator):
    discriminator.trainable = False
    gan_input = Input(shape=(100,))
    generated_image = generator(gan_input)
    gan_output = discriminator(generated_image)
    gan = Model(gan_input, gan_output)
    gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))
    return gan

# Build and compile the models
generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

# Train the GAN
def train_gan(epochs, batch_size):
    for epoch in range(epochs):
        noise = np.random.normal(0, 1, (batch_size, 100))
        generated_images = generator.predict(noise)
        real_images = X_train[np.random.randint(0, X_train.shape[0], batch_size)]

        X = np.concatenate([real_images, generated_images])
        y_dis = np.zeros(2 * batch_size)
        y_dis[:batch_size] = 0.9  # Label smoothing

        discriminator.trainable = True
        discriminator_loss = discriminator.train_on_batch(X, y_dis)

        noise = np.random.normal(0, 1, (batch_size, 100))
        y_gen = np.ones(batch_size)
        discriminator.trainable = False
        generator_loss = gan.train_on_batch(noise, y_gen)

        print(f'Epoch: {epoch + 1}, Generator Loss: {generator_loss}, Discriminator Loss: {discriminator_loss}')

# Train the GAN
train_gan(epochs=100, batch_size=128)

# Generate new images
def generate_images(rows, cols, save_path=None):
    noise = np.random.normal(0, 1, (rows * cols, 100))
    generated_images = generator.predict(noise)
    generated_images = generated_images.reshape(rows * cols, 28, 28)

    plt.figure(figsize=(10, 10))
    for i in range(rows * cols):
        plt.subplot(rows, cols, i + 1)
        plt.imshow(generated_images[i], cmap='gray')
        plt.axis('off')
    if save_path:
        plt.savefig(save_path)
    plt.show()

# Generate and display new images
generate_images(5, 5)
